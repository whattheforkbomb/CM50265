\section{Support Vector Machine (SVM)}
% Approach and results with respect to the SVM

% Why?
For classification problems, you ideally want the data to be linearly separable, i.e. you can use a single linear function defining a manifold (e.g. line, plane, cube, hyper-plane), from which you can separate the data based on the side it resides upon.\\
SVMs are used when data is not linearly separable in it's provided state. They work by taking a 'kernel', which transforms the data, extending it's dimensionality, such that it is then linearly separable within the new space.\\
For example, data that could be classified as being within a circle with radius r (vs outside the circle) can use a 2-D gaussian kernel centred on the circle's centre to create a 3'rd dimension with which to separate the data via a plane; points closer to the circle's centre / gaussian's mean will be given large values in the 3rd dimension.

Below are 3 Kernels that were used for the review sentiment analysis.

\subsection{Radial Basis Function (RBF)}
% What is this kernel (broadly)

% Used Built-in implementation

% - Display graphs with hyper-param tuning (gradient based)
%   - How to for linear?
%   - possibly do analysis on embedded features to determine best features?

% - Mis-classifications analysis:
%   - check the original sentences (e.g. sentence length, good & bad words)
%   - which features common to tp, fp, tn, fn, any sentences that don't correlate

%  metrics: {'accuracy': 0.9753333333333334, 'f1_score': 0.9757377049180328, 'sensitivity': 0.9674902470741222, 'false_negative_rate': 0.032509752925877766, 'false_positive_rate': 0.016415868673050615, 'specificity': 0.9835841313269493}

The RBF kernel used was the built-in implementation provided within \verb|sklearn.svm.SVC|.\\
The hyper-parameters for the RBF kernel model where \verb|C|: the regularisation parameter (L2), \verb|gamma|: a coefficient used by the kernel.\\
The hyper-parameters were optimised through 5-fold cross-validation, 

\begin{table}[h!]
    \centering
    \begin{tabular}[h]{c c|c|c|}
        \cline{3-4}
        & & \multicolumn{2}{c|}{Predicted} \\
        \cline{3-4}
        & & + & - \\
        \hline
        \multicolumn{1}{|c|}{\multirow{2}{3em}{Actual}} & + & 744 & 25 \\
        \cline{2-4}
        \multicolumn{1}{|c|}{} & - & 12 & 25 \\
        \hline
    \end{tabular}
    \caption{\label{tab:rbf_confusion}RBF Kernel Model Confusion Matrix}
\end{table}

\subsection{Polynomial}
% What is this kernel (broadly)

% Used Built-in implementation

% - Display graphs with hyper-param tuning (gradient based)
%   - How to for linear?
%   - possibly do analysis on embedded features to determine best features?

% - Mis-classifications analysis:
%   - check the original sentences (e.g. sentence length, good & bad words)
%   - which features common to tp, fp, tn, fn, any sentences that don't correlate

%  metrics: {'accuracy': 0.982, 'f1_score': 0.9822485207100592, 'sensitivity': 0.9713914174252276, 'false_negative_rate': 0.02860858257477243, 'false_positive_rate': 0.006839945280437756, 'specificity': 0.9931600547195623}

\begin{table}[h!]
    \centering
    \begin{tabular}[h]{c c|c|c|}
        \cline{3-4}
        & & \multicolumn{2}{c|}{Predicted} \\
        \cline{3-4}
        & & + & - \\
        \hline
        \multicolumn{1}{|c|}{\multirow{2}{3em}{Actual}} & + & 747 & 22 \\
        \cline{2-4}
        \multicolumn{1}{|c|}{} & - & 5 & 726 \\
        \hline
    \end{tabular}
    \caption{\label{tab:poly_confusion}Polynomial Kernel Model Confusion Matrix}
\end{table}

\subsection{Linear}
% What is this kernel (broadly)
% Top 3 positively correlated features:
% 300    0.282470
% 55     0.253391
% 5      0.225303
% Name: y, dtype: float64
% Top 3 negatively correlated features:
% 317   -0.285555
% 180   -0.248269
% 177   -0.247295
% Name: y, dtype: float64
% Used own implementation (what was the aim?)

% - Display graphs with hyper-param tuning (gradient based)
%   - How to for linear?
%   - possibly do analysis on embedded features to determine best features?

% - Mis-classifications analysis:
%   - check the original sentences (e.g. sentence length, good & bad words)
%   - which features common to tp, fp, tn, fn, any sentences that don't correlate

% Correct Predicitons: TP: 663, TN: 637
% Incorrect Predictions: FP: 94, FN: 106
%  metrics: {'accuracy': 0.8666666666666667, 'f1_score': 0.8689384010484927, 'sensitivity': 0.8621586475942783, 'false_negative_rate': 0.1378413524057217, 'false_positive_rate': 0.12859097127222982, 'specificity': 0.8714090287277702}
\begin{table}[h!]
    \centering
    \begin{tabular}[h]{c c|c|c|}
        \cline{3-4}
        & & \multicolumn{2}{c|}{Predicted} \\
        \cline{3-4}
        & & + & - \\
        \hline
        \multicolumn{1}{|c|}{\multirow{2}{3em}{Actual}} & + & 663 & 106 \\
        \cline{2-4}
        \multicolumn{1}{|c|}{} & - & 94 & 637 \\
        \hline
    \end{tabular}
    \caption{\label{tab:lin_confusion}Linear Kernel Model Confusion Matrix}
\end{table}

\subsection{Kernel Comparison}


