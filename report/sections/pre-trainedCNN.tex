% Data augmentation
%   Image rotation, zoom, shifting, mirroring
%   Could actually be own section as shared between both models?

% Model walkthrough
%   Final model shape (layer count, params)
%   Hyper-params (and potentially tuning?)
%   Model used (ResNet50) - why?
%   approaches to reduce over-fitting (drop-out, regularisation (still need to add))
%   approaches to reduce vanishing gradients (additive layers)
%   approaches to vanishing weights (leaky-relu)
%   FCN layers (different to model A?)
%   probs not image of graph (as massive), but can add to appendix


% Training and learning
%   Time to train, etc
%   Learning curves

% Link to colab notebook


% Some Data
% Epoch 18/50
% 125/125 [==============================] - 47s 374ms/step - loss: 122.8190 - age_output_loss: 105.4552 - gender_output_loss: 0.1736 - age_output_mean_absolute_error: 7.4054 - gender_output_binary_accuracy: 0.9243 - val_loss: 121.7092 - val_age_output_loss: 93.0191 - val_gender_output_loss: 0.2869 - val_age_output_mean_absolute_error: 7.0714 - val_gender_output_binary_accuracy: 0.8831
% Epoch 19/50
% 125/125 [==============================] - 48s 382ms/step - loss: 117.9897 - age_output_loss: 102.1514 - gender_output_loss: 0.1584 - age_output_mean_absolute_error: 7.3246 - gender_output_binary_accuracy: 0.9315 - val_loss: 117.9857 - val_age_output_loss: 89.8029 - val_gender_output_loss: 0.2818 - val_age_output_mean_absolute_error: 6.6650 - val_gender_output_binary_accuracy: 0.8841
% Epoch 20/50
% 125/125 [==============================] - 46s 367ms/step - loss: 111.8711 - age_output_loss: 96.3492 - gender_output_loss: 0.1552 - age_output_mean_absolute_error: 7.0517 - gender_output_binary_accuracy: 0.9380 - val_loss: 139.8109 - val_age_output_loss: 101.6454 - val_gender_output_loss: 0.3817 - val_age_output_mean_absolute_error: 7.1164 - val_gender_output_binary_accuracy: 0.8599
% Epoch 21/50
% 125/125 [==============================] - 46s 368ms/step - loss: 112.9045 - age_output_loss: 97.3385 - gender_output_loss: 0.1557 - age_output_mean_absolute_error: 7.0633 - gender_output_binary_accuracy: 0.9417 - val_loss: 143.0258 - val_age_output_loss: 112.8344 - val_gender_output_loss: 0.3019 - val_age_output_mean_absolute_error: 7.4501 - val_gender_output_binary_accuracy: 0.8760
% Epoch 22/50
% 125/125 [==============================] - 46s 365ms/step - loss: 111.8078 - age_output_loss: 98.6689 - gender_output_loss: 0.1314 - age_output_mean_absolute_error: 7.0413 - gender_output_binary_accuracy: 0.9455 - val_loss: 119.0313 - val_age_output_loss: 90.8313 - val_gender_output_loss: 0.2820 - val_age_output_mean_absolute_error: 6.6158 - val_gender_output_binary_accuracy: 0.8982
% Epoch 23/50
% 125/125 [==============================] - 47s 371ms/step - loss: 106.3928 - age_output_loss: 93.4850 - gender_output_loss: 0.1291 - age_output_mean_absolute_error: 6.9812 - gender_output_binary_accuracy: 0.9488 - val_loss: 140.9203 - val_age_output_loss: 112.3616 - val_gender_output_loss: 0.2856 - val_age_output_mean_absolute_error: 7.3017 - val_gender_output_binary_accuracy: 0.8881
% Epoch 24/50
%  125/125 [==============================] - 47s 377ms/step - loss: 102.8915 - age_output_loss: 89.4744 - gender_output_loss: 0.1342 - age_output_mean_absolute_error: 6.8606 - gender_output_binary_accuracy: 0.9452 - val_loss: 176.9170 - val_age_output_loss: 136.7507 - val_gender_output_loss: 0.4017 - val_age_output_mean_absolute_error: 8.1429 - val_gender_output_binary_accuracy: 0.8448

\section{Pre-trained Model}
\subsection{Architecture}
For our finetuned model we used ResNet50 as our base. This is because it is a relatively fast,
lightweight and high performing model. We used weights trained on imagenet as our initialisation.
The output of this base model was fed into a global average pooling layer and then a branch
 for each age and gender. Both branches used the same architecture as the dense layers in our 
 model.  

 \subsection{Training}
 The finetuned model was trained in the same manner as our model, with the same losses, loss weights,
 learning rate and optimizer. The model had a tendency to overfit quickly during training
 so we used early stopping to halt training once the validation loss increased for three 
 consecutive epochs. 
 
 \subsection{Performance}


\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{ModelB_AgeLearning_TunedHyperParams.png}
    \caption{\label{fig:ModelBPerformanceAge} The performance on age predicition for the finetuned model.}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{ModelB_GenderLearning_TunedHyperParams.png}
    \caption{\label{fig:ModelBPerformanceGender} The performance on gender predicition for the finetuned model.}
\end{figure}