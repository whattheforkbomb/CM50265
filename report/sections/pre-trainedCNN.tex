% Data augmentation
%   Image rotation, zoom, shifting, mirroring
%   Could actually be own section as shared between both models?

% Model walkthrough
%   Final model shape (layer count, params)
%   Hyper-params (and potentially tuning?)
%   Model used (ResNet50) - why?
%   approaches to reduce over-fitting (drop-out, regularisation (still need to add))
%   approaches to reduce vanishing gradients (additive layers)
%   approaches to vanishing weights (leaky-relu)
%   FCN layers (different to model A?)
%   probs not image of graph (as massive), but can add to appendix


% Training and learning
%   Time to train, etc
%   Learning curves

% Link to colab notebook


% Some Data
% Epoch 18/50
% 125/125 [==============================] - 47s 374ms/step - loss: 122.8190 - age_output_loss: 105.4552 - gender_output_loss: 0.1736 - age_output_mean_absolute_error: 7.4054 - gender_output_binary_accuracy: 0.9243 - val_loss: 121.7092 - val_age_output_loss: 93.0191 - val_gender_output_loss: 0.2869 - val_age_output_mean_absolute_error: 7.0714 - val_gender_output_binary_accuracy: 0.8831
% Epoch 19/50
% 125/125 [==============================] - 48s 382ms/step - loss: 117.9897 - age_output_loss: 102.1514 - gender_output_loss: 0.1584 - age_output_mean_absolute_error: 7.3246 - gender_output_binary_accuracy: 0.9315 - val_loss: 117.9857 - val_age_output_loss: 89.8029 - val_gender_output_loss: 0.2818 - val_age_output_mean_absolute_error: 6.6650 - val_gender_output_binary_accuracy: 0.8841
% Epoch 20/50
% 125/125 [==============================] - 46s 367ms/step - loss: 111.8711 - age_output_loss: 96.3492 - gender_output_loss: 0.1552 - age_output_mean_absolute_error: 7.0517 - gender_output_binary_accuracy: 0.9380 - val_loss: 139.8109 - val_age_output_loss: 101.6454 - val_gender_output_loss: 0.3817 - val_age_output_mean_absolute_error: 7.1164 - val_gender_output_binary_accuracy: 0.8599
% Epoch 21/50
% 125/125 [==============================] - 46s 368ms/step - loss: 112.9045 - age_output_loss: 97.3385 - gender_output_loss: 0.1557 - age_output_mean_absolute_error: 7.0633 - gender_output_binary_accuracy: 0.9417 - val_loss: 143.0258 - val_age_output_loss: 112.8344 - val_gender_output_loss: 0.3019 - val_age_output_mean_absolute_error: 7.4501 - val_gender_output_binary_accuracy: 0.8760
% Epoch 22/50
% 125/125 [==============================] - 46s 365ms/step - loss: 111.8078 - age_output_loss: 98.6689 - gender_output_loss: 0.1314 - age_output_mean_absolute_error: 7.0413 - gender_output_binary_accuracy: 0.9455 - val_loss: 119.0313 - val_age_output_loss: 90.8313 - val_gender_output_loss: 0.2820 - val_age_output_mean_absolute_error: 6.6158 - val_gender_output_binary_accuracy: 0.8982
% Epoch 23/50
% 125/125 [==============================] - 47s 371ms/step - loss: 106.3928 - age_output_loss: 93.4850 - gender_output_loss: 0.1291 - age_output_mean_absolute_error: 6.9812 - gender_output_binary_accuracy: 0.9488 - val_loss: 140.9203 - val_age_output_loss: 112.3616 - val_gender_output_loss: 0.2856 - val_age_output_mean_absolute_error: 7.3017 - val_gender_output_binary_accuracy: 0.8881
% Epoch 24/50
%  125/125 [==============================] - 47s 377ms/step - loss: 102.8915 - age_output_loss: 89.4744 - gender_output_loss: 0.1342 - age_output_mean_absolute_error: 6.8606 - gender_output_binary_accuracy: 0.9452 - val_loss: 176.9170 - val_age_output_loss: 136.7507 - val_gender_output_loss: 0.4017 - val_age_output_mean_absolute_error: 8.1429 - val_gender_output_binary_accuracy: 0.8448

\section{Model B - Using Pre-Trained CNN}
\subsection{Architecture}
For our pre-trained model we used ResNet50 as our base. This is because it is a relatively fast, lightweight and high performing model (with respect to ImageNet top 5 rating).\\
We used weights trained on ImageNet as our initial weights.
These weights were not frozen in order to allow the model to learn features specific to age and gender prediction.\\
The output of this base model is fed into 2 branches (one for gender, the other for age).
Each performs an additional padded convolution, before being flattened and passed on towards their own FCN layers (with one output layer and 2 hidden layers).
All the FCN Dense layers made use of dropout and regularisation to reduce over-fitting.
\begin{figure}[h]
    \centering
    \includegraphics[height=0.5\textheight]{ModelBGraph_sample_simplified_dropouts_truncated.png}
\end{figure}

\subsection{Training}
The pre-trained model was trained in the same manner as Model A, with the same losses, loss weights, and optimizer. 

To limit overfitting a stop early callback was used to end training if the validation loss failed to improve over 5 consecutive epochs.

Hyper-Parameters were tuned in the same manner as for Model A.\\
Hyper-parameters tuned were:
\begin{enumerate}
    \item Initial Learning rate
    \item Flatten Vs Global Pooling: whether to flatten the 3D output from the final convolution layers
    \item Feature depth of final convolution layer 
    \item Number of Units for first FCN layer 
    \item Dropout rate
    \item Regularisation 
\end{enumerate}
Once tuning completed, we rebuilt and trained the model with the tuned hyper-params fixed.


\subsection{Performance}
The trace of the final epoch is below.

\begin{verbatim}
Epoch 31/50
125/125 [==============================] 
- 37s 296ms/step 
- loss: 159.7228 
- age_output_loss: 106.7853 
- gender_output_loss: 0.1204 
- age_output_mean_absolute_error: 7.3058 
- gender_output_binary_accuracy: 0.9507 
- val_loss: 154.9256 
- val_age_output_loss: 86.5945 
- val_gender_output_loss: 0.3250 
- val_age_output_mean_absolute_error: 6.4584 
- val_gender_output_binary_accuracy: 0.8871
    
\end{verbatim}

The pre-trained model performed slightly better than our model on both tasks on the validation data.
It achieved an accuracy of 89\% on gender prediction and a mean squared error of 6.5 on age
prediction. It can be seen in \autoref{fig:ModelBPerformance} to overfit on gender prediction but not on age prediction.


\begin{figure}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=0.7\textwidth]{Model_B_AgeLearning.png}
        \caption{\label{fig:ModelBPerformanceAge} The performance on age prediction for the pre-trained model.}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
    \includegraphics[width=0.7\textwidth]{Model_B_GenderLearning.png}
    \caption{\label{fig:ModelBPerformanceGender} The performance on gender prediction for the pre-trained model.}
    \end{subfigure}
    \label{fig:ModelBPerformance}
    \caption{Learning curves observed training Model B}
\end{figure}

