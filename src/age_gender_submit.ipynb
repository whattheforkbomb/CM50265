{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_gender_submit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRYwLR3vqLz"
      },
      "source": [
        "# Age Estimation and Gender Classification\n",
        "\n",
        "In this assignment, you will train CNN models to estimate a person's age and gender by given a face image. Please read carefully all the instructions before you start to write your code.\n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "You need train two CNN models:\n",
        "- one is defined by you with a few restrictions and be trained from scratch, save it as `age_gender_A.h5`\n",
        "- the other is to finetune a pretrained model, save it as `age_gender_B.h5`\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "Your models will be trained and validated on a folder `train_val/` containing 5,000 labeled face images (size: 128 x 128), originated from the UTKFace dataset. During marking, your code will be tested on unseen test data. \n",
        "\n",
        "**Performance metric**\n",
        "\n",
        "The metrics for measuring the performance on the test set are:\n",
        "- age estimation: MAE (Mean Absolute Error)\n",
        "- gender classification: accuracy\n",
        "\n",
        "**Please use the GPU time wisely.**\n",
        "\n",
        "Just be aware that there is some limit of free GPU usage (It is said the users can use up to 12 hours in row. But many people found they reached its limit far less than 12 hours.). Therefore, I would give you three suggestions to mimimise the risk of reaching the limit.\n",
        "\n",
        "1. Make sure you have a stable internet connection.\n",
        "2. Double check all the hyperparameters are good before you start to train the model.\n",
        "3. According to my experience, each model should be trained in less than 2 hours. If much longer than that, you'd better consider adjusting the architecture."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from os import listdir\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "image_width = image_height = 128\n",
        "image_channels = 3 # RGB\n",
        "data_frame_labels = ['Filenames', 'Age', 'Gender']"
      ],
      "metadata": {
        "id": "UUxcD3t_iVIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOAXA2CdQ8Pb"
      },
      "source": [
        "## Setting Up: Mount the google drive\n",
        "Mount your google drive to the notebook. \n",
        "\n",
        "Also don't forget to **enable GPU** before your training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCwBWDsMQwyb"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "content_dir = \"/content/drive/MyDrive/ML2CW1/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data locally\n",
        "#### remove before submission\n",
        "content_dir = '/mnt/g/My Drive/'"
      ],
      "metadata": {
        "id": "RPyFjyp3lk4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = content_dir + \"train_val/\"\n",
        "file_names = listdir(image_dir)\n",
        "\n",
        "image_paths = list(map(lambda x : image_dir + x, file_names))\n",
        "\n",
        "labels = []\n",
        "for name in file_names:\n",
        "  label = name.split(\"_\")[:2]\n",
        "  labels.append(label)"
      ],
      "metadata": {
        "id": "mRPpxHPmooOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBRVYYhRRINA"
      },
      "source": [
        "## Visualize a few photos\n",
        "It is always benificial to know your data well before you start. Here display a few (at least 20) images together with its corresponding age and gender from the `train_val/` folder to have a first impression of the dataset. You may also check what the size of the images are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zA1kSeoReXJ"
      },
      "source": [
        "imgs_to_show = []\n",
        "num_images = 20\n",
        "\n",
        "random_image_paths = random.sample(image_paths, num_images)\n",
        "\n",
        "for i in range(num_images):\n",
        "  imgs_to_show.append(mpimg.imread(random_image_paths[i]))\n",
        "\n",
        "axes=[]\n",
        "\n",
        "for i in range(20):\n",
        "  image = imgs_to_show[i]\n",
        "  label = random_image_paths[i].split(\"/\")[-1].split(\"_\")[:2]\n",
        "  fig = plt.figure()\n",
        "  plt.xlabel(\"Age: \" + label[0] + \" Gender: \" + label[1])\n",
        "  plt.imshow(image)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp_QcvuTRUqq"
      },
      "source": [
        "## Rearrange the dataset\n",
        "You may do any arrangement for the dataset to suit your later process, such as splitting into training set and validation set, saving the gender labels and age some how, and so on.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOkUt8_Uu8q"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "ages = [np.asarray(item[0]).astype(float) for item in labels]\n",
        "genders = [np.asarray(item[1]).astype(float) for item in labels]\n",
        "data = np.array([image_paths, ages, genders]).T\n",
        "df = pd.DataFrame(data = data, columns = data_frame_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YUBgGWAUHXp"
      },
      "source": [
        "## STEP1: Data pre-processing\n",
        "Now you need do some pre-processing before feeding data into a CNN network. You may consider:\n",
        "\n",
        "1.\tRescale the pixel values (integers between 0 and 255) to [0,1]. **You must do this rescaling.** Otherwise the testing performance will be affected significantly, as the test images will be rescaling in this way. \n",
        "2.\tData augmentation.\n",
        "\n",
        "**Don't rescale the age to [0,1].** Otherwise the testing performance will be affected significantly, as the original age is used in the testing stage. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0BC0YXzUyvT"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "\n",
        "image_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.1, horizontal_flip=True, validation_split = 0.2)\n",
        "train_generator = image_datagen.flow_from_dataframe(df, x_col=data_frame_labels[0], y_col=data_frame_labels[1:], target_size=(image_width,image_height), color_mode='rgb', class_mode='raw', subset='training', batch_size=50)\n",
        "validation_generator = image_datagen.flow_from_dataframe(df, x_col=data_frame_labels[0], y_col=data_frame_labels[1:], target_size=(image_width,image_height), color_mode='rgb', class_mode='raw', subset='validation', batch_size=50)\n",
        "\n",
        "print(train_generator.n, train_generator.batch_size, train_generator.n // train_generator.batch_size)\n",
        "print(validation_generator.n, validation_generator.batch_size, validation_generator.n // validation_generator.batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gen_wrapped():\n",
        "  batch = train_generator.next()\n",
        "  casted = (np.array(batch[0]), np.array([[int(float(item[0])), int(float(item[1]))] for item in batch[1][:]]))\n",
        "  while True:\n",
        "    yield casted\n",
        "\n",
        "def val_gen_wrapped():\n",
        "  batch = validation_generator.next()\n",
        "  casted = (np.array(batch[0]), np.array([[int(float(item[0])), int(float(item[1]))] for item in batch[1][:]]))\n",
        "  while True:\n",
        "    yield casted\n",
        "\n",
        "\n",
        "sample = next(train_gen_wrapped())\n",
        "sample[1][0:5]\n"
      ],
      "metadata": {
        "id": "_gjYd-t7qkQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaH0dLz-UzpT"
      },
      "source": [
        "## STEP2A: Build your own CNN network\n",
        "Define your own CNN for classifying the gender and predicting the age. Though there are two tasks, you need **only one CNN model, but with two outputs** - you may search online for solution.\n",
        "\n",
        "There are a few restrictions about your network as follows.\n",
        "1.\tThe input size must be 128 x 128 x 3, which means you **should not resize** the original images. This is because my test code relies on this particular input size. Any other size will cause problem in the testing stage.\n",
        "2.  Please treat the gender classification as a binary problem, i.e., **the output layer for the gender branch has only 1 unit**, instead of 2 (though it is correct to treat the gender classification as a mutli-class problem where class number is 2, the last layer has 2 units). This is because my test code only works for the 1-unit-last-layer gender branch setting. \n",
        "3.\tThe size of feature maps being fed to the first fully connected layer must be less than 10 x 10, while there is no number limitation about the depth.\n",
        "4.\tYou may choose any techniques for preventing overfitting. \n",
        "\n",
        "In the end of the cell, use `modelA.summary()` to output the model architecture. You may also use `plot_model()` to visualize its architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atYurdRBU64d"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "\n",
        "# Can only really tune hyper-params, everything-else is managed by Keras.\n",
        "# Hyper-params:\n",
        "# - Kernel Size (1st layer must be 10x10 or smaller)\n",
        "# - Number of Layers (Tho kinda dependent on kernal sizes? Must also be reasonable, pressume nothing crazy like 100 layers...)\n",
        "# - Activation Function (probably some variation on ReLU, e.g. LeakyReLU)\n",
        "# - Pooling Layers (Where to use, e.g. between each layer, or spread-out a bit)\n",
        "# - Number of 'Features', e.g. how many kernals for a given layer\n",
        "# - Using Single Layer & Kernel Size Vs Multiple Layers With Smaller Kernels (e.g. one 5x5 is equivilent to two 3x3 layers (with no pooling), latter reduces number of params, but obviously doubles number of layers)\n",
        "# - Where to branch (e.g. how many layers do we share with each branch: split right away, or at point of classification? Basically how many features reused between branches)\n",
        "# - \n",
        "\n",
        "# Not sure how best to tune the hyper-params to ensure avoid over-fitting to data, e.g. not just re-running with different config over-and-over.\n",
        "\n",
        "# Train w/ & w/out for comparision w/in the report, see if any actual performance benefits?\n",
        "#greyscale = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs) # Might want to branch here as colour could be helpful to distinguish grey/white hair from other colours, might be helpful for age branch\n",
        "\n",
        "# Need one branch for age, other for gender\n",
        "#   Worth encapsulating into methods to create each branch?\n",
        "\n",
        "# Conv2d args (at least obviously important ones): https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "# tf.keras.layers.Conv2D(\n",
        "#     filters,     # Number of filters/features, depth of next layer\n",
        "#     kernel_size, # Can either be int: n for n*n, or (int, int): (n, m) for n*m, can also do additional dimensions, e.g. to try and reduce the depth of prior layers\n",
        "#     strides=(1, 1),\n",
        "#     padding=\"valid\",\n",
        "#     ...\n",
        "#     activation=None,\n",
        "#     ...\n",
        "# )\n",
        "\n",
        "# MaxPooling2D & AveragePooling2D args: https://keras.io/api/layers/pooling_layers/max_pooling2d/  https://keras.io/api/layers/pooling_layers/average_pooling2d/\n",
        "# tf.keras.layers.MaxPooling2D/AveragePooling2D(\n",
        "#     pool_size=(2, 2), \n",
        "#     strides=None, \n",
        "#     padding=\"valid\", \n",
        "#     ...\n",
        "# )\n",
        "\n",
        "# Layer Dimensions Calculations:\n",
        "#   new_width  = (old_width - kernel_width + (2 * padding_x)) / (stride_x + 1)\n",
        "#   new_height = (old_height - kernel_height + (2 * padding_y)) / (stride_y + 1)\n",
        "#   new_depth  = old_depth # though was also *number_of_features, but seems these arre flattened for each feature\n",
        "\n",
        "def create_modelA(greyscale):\n",
        "  inputs = keras.Input((image_width, image_height, image_channels))\n",
        "\n",
        "  if (greyscale == 2): # only apply greyscale to gender branch \n",
        "    gender_inputs = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
        "    gender_branch = create_modelA_common_layers(gender_inputs)\n",
        "    gender_branch = create_gender_branch(gender_branch)\n",
        "\n",
        "    age_branch = create_modelA_common_layers(inputs)\n",
        "    age_branch = create_age_branch(age_branch)\n",
        "  else: # greyscale for both or neither branch\n",
        "    # greyscale for both branches\n",
        "    greyscale_layer = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs) if greyscale == 1 else inputs\n",
        "    common_layers = create_modelA_common_layers(inputs)\n",
        "\n",
        "    gender_branch = create_gender_branch(common_layers)\n",
        "    age_branch = create_age_branch(common_layers)\n",
        "\n",
        "  # Creating 1 model w/ two branches per https://pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/\n",
        "  return keras.Model(inputs=inputs, outputs=[age_branch, gender_branch], name=\"ModelA\")\n",
        "\n",
        "def create_modelA_common_layers(inputs):\n",
        "  \n",
        "  common_layers = layers.Conv2D(256, 5)(inputs) # 124, 124, 512\n",
        "  common_layers = layers.LeakyReLU(0.2)(common_layers)\n",
        "  common_layers = layers.Conv2D(128, 5)(common_layers) # 120, 120, 512\n",
        "  # common_layers = layers.LeakyReLU(0.2)(common_layers)\n",
        "  # common_layers = layers.Conv2D(128, 5)(common_layers) # 58, 58, 1024\n",
        "  common_layers = layers.BatchNormalization(axis=1)(common_layers)\n",
        "  common_layers = layers.MaxPooling2D((9,9), strides=(2,2))(common_layers) # 50, 50, 1024\n",
        "\n",
        "  common_layers_a = layers.Conv2D(64, 5)(common_layers) # 46, 46, 64\n",
        "  common_layers_a = layers.Conv2D(64, 5)(common_layers_a)  # 42, 42, 64\n",
        "  common_layers_a = layers.LeakyReLU(0.2)(common_layers_a)\n",
        "\n",
        "  common_layers_b = layers.Conv2D(64, 9)(common_layers) # 42, 42, 64\n",
        "  common_layers_b = layers.LeakyReLU(0.2)(common_layers_b)\n",
        "\n",
        "  common_layers = layers.Add()([common_layers_a, common_layers_b])\n",
        "  common_layers = layers.BatchNormalization(axis=1)(common_layers)\n",
        "\n",
        "  common_layers = layers.MaxPooling2D((7,7), (4,4))(common_layers) # 9, 9, 64\n",
        "  # common_layers = layers.Conv2D(128, 3)(common_layers) # 7, 7, 128\n",
        "  \n",
        "  common_layers_c = layers.Conv2D(128, 3, padding='same')(common_layers) # 7, 7, 128 # padding to keep output same size as input\n",
        "  common_layers_c = layers.LeakyReLU(0.2)(common_layers_c)\n",
        "  common_layers_c = layers.Conv2D(64, 3, padding='same')(common_layers_c) # 7, 7, 64\n",
        "  common_layers_c = layers.LeakyReLU(0.2)(common_layers_c)\n",
        "  common_layers_c = layers.Conv2D(64, 3, padding='same')(common_layers_c) # 7, 7, 64\n",
        "  common_layers_c = layers.LeakyReLU(0.2)(common_layers_c)\n",
        "  common_layers_c = layers.Conv2D(32, 3, padding='same')(common_layers_c) # 7, 7, 32\n",
        "  common_layers_c = layers.BatchNormalization(axis=1)(common_layers_c)\n",
        "\n",
        "  common_layers_d = layers.Conv2D(128, 3, padding='same')(common_layers) # 7, 7, 128 # padding to keep output same size as input\n",
        "  common_layers_d = layers.LeakyReLU(0.2)(common_layers_d)\n",
        "  common_layers_d = layers.Conv2D(32, 3, padding='same')(common_layers_d) # 7, 7, 32\n",
        "  common_layers_d = layers.BatchNormalization(axis=1)(common_layers_d) \n",
        "  \n",
        "  common_layers = layers.Add()([common_layers_c, common_layers_d])\n",
        "  common_layers = layers.GlobalAveragePooling2D()(common_layers)\n",
        "\n",
        "  return common_layers\n",
        "\n",
        "# Probably just need fully connected layers here, no more convolutions?\n",
        "def create_gender_branch(inputs):\n",
        "  gender_branch = layers.Dense(128)(inputs)\n",
        "  gender_branch = layers.LeakyReLU(0.2)(gender_branch)\n",
        "\n",
        "  gender_branch_a = layers.Dense(256)(gender_branch)\n",
        "  gender_branch_a = layers.LeakyReLU(0.2)(gender_branch_a)\n",
        "  gender_branch_a = layers.Dropout(0.05)(gender_branch_a)\n",
        "  gender_branch_a = layers.Dense(64)(gender_branch_a)\n",
        "  gender_branch_a = layers.LeakyReLU(0.2)(gender_branch_a)\n",
        "  gender_branch_a = layers.Dropout(0.05)(gender_branch_a)\n",
        "  gender_branch_a = layers.Dense(32)(gender_branch_a)\n",
        "  gender_branch_a = layers.LeakyReLU(0.2)(gender_branch_a)\n",
        "  gender_branch_a = layers.Dropout(0.05)(gender_branch_a)\n",
        "\n",
        "  gender_branch_b = layers.Dense(32)(gender_branch)\n",
        "  gender_branch_b = layers.LeakyReLU(0.2)(gender_branch_b)\n",
        "\n",
        "  gender_branch = layers.Add()([gender_branch_a, gender_branch_b])\n",
        "  gender_branch = layers.LeakyReLU(0.2)(gender_branch)\n",
        "  gender_branch = layers.Dropout(0.05)(gender_branch)\n",
        "  gender_branch = layers.Dense(2)(gender_branch)\n",
        "  gender_branch = layers.ReLU()(gender_branch)\n",
        "  gender_branch = layers.Dropout(0.05)(gender_branch)\n",
        "  gender_branch = layers.Dense(1)(gender_branch)\n",
        "  gender_branch = layers.Activation('sigmoid', name='gender_output')(gender_branch)\n",
        "  return gender_branch\n",
        "\n",
        "def create_age_branch(inputs):\n",
        "  age_branch = layers.Dense(256)(inputs)\n",
        "  age_branch = layers.LeakyReLU(0.2)(age_branch)\n",
        "  age_branch = layers.Dropout(0.05)(age_branch)\n",
        "  age_branch = layers.Dense(128)(age_branch)\n",
        "  age_branch = layers.LeakyReLU(0.2)(age_branch)\n",
        "  age_branch = layers.Dropout(0.05)(age_branch)\n",
        "  age_branch = layers.Dense(16)(age_branch)\n",
        "  age_branch = layers.LeakyReLU(0.2)(age_branch)\n",
        "  age_branch = layers.Dense(1, name='age_output')(age_branch)\n",
        "\n",
        "  return age_branch\n",
        "\n",
        "modelA = create_modelA(0)\n",
        "\n",
        "modelA.summary()\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(modelA, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvxCap5OVNEG"
      },
      "source": [
        "## STEP3A: Compile and train your model\n",
        "Compile and train your model here. \n",
        "Save your model by `modelA.save(your_model_folder+\"age_gender_A.h5\")` after training. \n",
        "\n",
        "**DON'T use any other name for your model file.** This is because my test code relies on this particular model name. Any other file name will cause problem in the testing stage.\n",
        "\n",
        "**Save the model with `save()` instead of `save_weights()`.** This is because I will load the model by \n",
        "\n",
        "`modelA = load_model(model_folder+\"age_gender_A.h5\")`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7rWAbMoVPMw"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "\n",
        "losses = {\n",
        "\t\"age_output\": keras.losses.MeanAbsoluteError(),\n",
        "  \"gender_output\": keras.losses.BinaryCrossentropy()\n",
        "}\n",
        "metrics= {\n",
        "  \"age_output\": keras.metrics.MeanAbsoluteError(),\n",
        "  \"gender_output\": keras.metrics.BinaryAccuracy()\n",
        "}\n",
        "\n",
        "# compile model\n",
        "modelA_compiled = modelA.compile(loss=losses, optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=metrics)\n",
        "print(\"Compiling Model A\")\n",
        "\n",
        "modelA_epoch_count = 50 # ?\n",
        "modelA_train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
        "modelA_val_steps_per_epoch = validation_generator.n // validation_generator.batch_size\n",
        "\n",
        "print(\"training steps per epoch: {}\\nvalidation steps per epoch: {}\".format(modelA_train_steps_per_epoch, modelA_val_steps_per_epoch))\n",
        "\n",
        "print(\"Fitting Model A\")\n",
        "modelA_history = modelA.fit(\n",
        "    x=train_gen_wrapped(),\n",
        "    validation_data=val_gen_wrapped(),\n",
        "    epochs=modelA_epoch_count,\n",
        "    steps_per_epoch=modelA_train_steps_per_epoch,\n",
        "    validation_steps=modelA_val_steps_per_epoch\n",
        ")\n",
        "\n",
        "modelA.save(content_dir+\"age_gender_A.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX9woxxCVPj-"
      },
      "source": [
        "## STEP4A: Draw the learning curves\n",
        "Draw four figures as follows\n",
        "1.\tThe loss of the gender classification over the training and validation set\n",
        "2.\tThe accuracy of the gender classification over the training and validation set\n",
        "3.\tThe loss of the age estimation over the training and validation set\n",
        "4.\tThe MAE of the age estimation over the training and validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pl5bSA5VT3Y"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "epochs = np.linspace(0, modelA_epoch_count, modelA_epoch_count)\n",
        "\n",
        "fig, (gender_loss, gender_accuracy) = plt.subplots(2, sharex=True)\n",
        "fig.suptitle(\"Gender Learning Curves\")\n",
        "fig.set_size_inches(12,8)\n",
        "\n",
        "gender_loss.set_xlabel(\"Epoch\")\n",
        "gender_loss.set_ylabel(\"Gender Loss\")\n",
        "gender_loss.plot(epochs, modelA_history.history['gender_output_loss'], label='training')\n",
        "gender_loss.plot(epochs, modelA_history.history['val_gender_output_loss'], label='validation')\n",
        "gender_loss.legend()\n",
        "\n",
        "gender_accuracy.set_xlabel(\"Epoch\")\n",
        "gender_accuracy.set_ylabel(\"Gender Accuracy\")\n",
        "gender_accuracy.plot(epochs, modelA_history.history['gender_output_binary_accuracy'], label='training')\n",
        "gender_accuracy.plot(epochs, modelA_history.history['val_gender_output_binary_accuracy'], label='validation')\n",
        "gender_accuracy.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig, (age_loss, age_mae) = plt.subplots(2, sharex=True)\n",
        "fig.suptitle(\"Age Learning Curves\")\n",
        "fig.set_size_inches(12,8)\n",
        "\n",
        "age_loss.set_xlabel(\"Epoch\")\n",
        "age_loss.set_ylabel(\"Age Loss\")\n",
        "age_loss.plot(epochs, modelA_history.history['age_output_loss'], label='training')\n",
        "age_loss.plot(epochs, modelA_history.history['val_age_output_loss'], label='validation')\n",
        "age_loss.legend()\n",
        "\n",
        "age_mae.set_xlabel(\"Epoch\")\n",
        "age_mae.set_ylabel(\"Age Mean Absolute Error (MEA)\")\n",
        "age_mae.plot(epochs, modelA_history.history['age_output_mean_absolute_error'], label='training')\n",
        "age_mae.plot(epochs, modelA_history.history['val_age_output_mean_absolute_error'], label='validation')\n",
        "age_mae.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fCO79ViVUkX"
      },
      "source": [
        "## STEP2B: Build a CNN network based on a pre-trained model \n",
        "Choose one existing CNN architecture pre-trained on ImageNet, and fine-tune on this dataset.\n",
        "\n",
        "The same as required in Model A, **donâ€™t resize the input image size**. **The output layer for the gender branch is set to have only 1 unit**. \n",
        "\n",
        "In the end of the cell, use `modelB.summary()` to output the model architecture. You may also use `plot_model()` to visualize its architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0twFrc4jVi2E"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "\n",
        "# list of available models: https://keras.io/api/applications/\n",
        "import tensorflow.keras.applications.resnet50 as ResNet50 # quick, lighweight, and fairly accurate  \n",
        "\n",
        "inputs_b = keras.Input((image_width, image_height, image_channels))\n",
        "base_resnet50 = ResNet50.ResNet50(input_tensor=inputs_b, weights='imagenet', include_top=False)\n",
        "\n",
        "globalPool = layers.GlobalAveragePooling2D()(base_resnet50.output)\n",
        "\n",
        "gender_branch = create_gender_branch(globalPool)\n",
        "age_branch = create_age_branch(globalPool)\n",
        "\n",
        "modelB = keras.Model(inputs=base_resnet50.inputs, outputs=[age_branch, gender_branch])\n",
        "\n",
        "modelB.summary()\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(modelB, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqWfCAzVjPk"
      },
      "source": [
        "## STEP3B: Compile and train your model\n",
        "Compile and train your model here. \n",
        "Save your model to `age_gender_B.h5` after training. \n",
        "\n",
        "**DON'T use any other name for your model file.** This is because my test code relies on this particular model name. Any other file name will cause problem in the testing stage.\n",
        "\n",
        "**Also, save the model with `save()` instead of `save_weights()`.** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQlYE1aWVmml"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "losses = {\n",
        "  \"age_output\": keras.losses.MeanAbsoluteError(),\n",
        "\t\"gender_output\": keras.losses.BinaryCrossentropy()\n",
        "}\n",
        "metrics= {\n",
        "  \"age_output\": keras.metrics.MeanAbsoluteError(),\n",
        "  \"gender_output\": keras.metrics.BinaryAccuracy()\n",
        "}\n",
        "\n",
        "modelB_compiled = modelB.compile(loss=losses, optimizer='adam', metrics=metrics)\n",
        "print(\"Compiling Model B\")\n",
        "\n",
        "modelB_epoch_count = 50 # ?\n",
        "modelB_train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
        "modelB_val_steps_per_epoch = validation_generator.n // validation_generator.batch_size\n",
        "\n",
        "modelB_history = modelB.fit(\n",
        "    x=train_gen_wrapped(),\n",
        "    validation_data=val_gen_wrapped(),\n",
        "    epochs=modelB_epoch_count,\n",
        "    steps_per_epoch=modelB_train_steps_per_epoch,\n",
        "    validation_steps=modelB_val_steps_per_epoch\n",
        ")\n",
        "\n",
        "modelB.save(content_dir+\"age_gender_B.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdRlobSlVnBi"
      },
      "source": [
        "## STEP4B: Draw the learning curve\n",
        "Draw four figures as follows\n",
        "1.\tThe loss of the gender classification over the training and validation set\n",
        "2.\tThe accuracy of the gender classification over the training and validation set\n",
        "3.\tThe loss of the age estimation over the training and validation set\n",
        "4.\tThe MAE of the age estimation over the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T_uTOQkVrAB"
      },
      "source": [
        "#\n",
        "# Add your code here\n",
        "#\n",
        "epochs = np.linspace(0, modelB_epoch_count, modelB_epoch_count)\n",
        "\n",
        "fig, (gender_loss, gender_accuracy) = plt.subplots(2, sharex=True)\n",
        "fig.suptitle(\"Gender Learning Curves\")\n",
        "fig.set_size_inches(12,8)\n",
        "\n",
        "gender_loss.set_xlabel(\"Epoch\")\n",
        "gender_loss.set_ylabel(\"Gender Loss\")\n",
        "gender_loss.plot(epochs, modelB_history.history['gender_output_loss'], label='training')\n",
        "gender_loss.plot(epochs, modelB_history.history['val_gender_output_loss'], label='validation')\n",
        "gender_loss.legend()\n",
        "\n",
        "gender_accuracy.set_xlabel(\"Epoch\")\n",
        "gender_accuracy.set_ylabel(\"Gender Accuracy\")\n",
        "gender_accuracy.plot(epochs, modelB_history.history['gender_output_binary_accuracy'], label='training')\n",
        "gender_accuracy.plot(epochs, modelB_history.history['val_gender_output_binary_accuracy'], label='validation')\n",
        "gender_accuracy.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig, (age_loss, age_mae) = plt.subplots(2, sharex=True)\n",
        "fig.suptitle(\"Age Learning Curves\")\n",
        "fig.set_size_inches(12,8)\n",
        "\n",
        "age_loss.set_xlabel(\"Epoch\")\n",
        "age_loss.set_ylabel(\"Age Loss\")\n",
        "age_loss.plot(epochs, modelB_history.history['age_output_loss'], label='training')\n",
        "age_loss.plot(epochs, modelB_history.history['val_age_output_loss'], label='validation')\n",
        "age_loss.legend()\n",
        "\n",
        "age_mae.set_xlabel(\"Epoch\")\n",
        "age_mae.set_ylabel(\"Age Mean Absolute Error (MEA)\")\n",
        "age_mae.plot(epochs, modelB_history.history['age_output_mean_absolute_error'], label='training')\n",
        "age_mae.plot(epochs, modelB_history.history['val_age_output_mean_absolute_error'], label='validation')\n",
        "age_mae.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67UhgpceVrv2"
      },
      "source": [
        "## STEP5: Evaluate the model on the test set\n",
        "I will add my test code here to test the two models you trained. The test set will not be available before your submission. \n",
        "\n",
        "The metrics for measuring the performance on the test set are:\n",
        "- age estimation: MAE (Mean Absolute Error)\n",
        "- gender classification: accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rh5DlraV1aj"
      },
      "source": [
        "#\n",
        "# Don't add code in this cell when submitting this file\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}